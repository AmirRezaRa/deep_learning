# -*- coding: utf-8 -*-
"""Malaria_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13gKa9SRCph-BY5k1XcGp-BoAYQvLjGMn
"""

import tensorflow as tf
import numpy as np
import cv2
import matplotlib.pyplot as plt
import tensorflow_datasets as tfds
import tensorflow_probability as tfp
from tensorflow.keras.layers import InputLayer, Flatten, Dense, Conv2D, MaxPool2D, Dropout, BatchNormalization, Input, Layer, RandomFlip, RandomRotation, Resizing, Rescaling
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import BinaryCrossentropy
from tensorflow.keras.models import Model
import albumentations as A
import sklearn
from sklearn.metrics import confusion_matrix, roc_curve
import seaborn as sns
from tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall, AUC, FalseNegatives, FalsePositives, TrueNegatives, TruePositives,binary_accuracy
from tensorflow.keras.callbacks import Callback, CSVLogger, EarlyStopping, LearningRateScheduler
from tensorboard.plugins.hparams import api as hp
import wandb
from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint
import random

"""***wandb install, login and initialization***"""

!pip install wandb
!wandb login

wandb.init(
    # set the wandb project where this run will be logged
    project="Malaria_Detection",
     config={
        'learning_rate':0.001,
        "n_dense_1": 512,
        "activation_1": "relu",
        "dropout": random.uniform(0.01, 0.80),
        "n_dense_2": 10,
        "activation_2": "softmax",
        "optimizer": "sgd",
        "loss": "sparse_categorical_crossentropy",
        "metric": "accuracy",
        "pool_size":2,
        "epoch": 8,
        "batch_size": 256
    }
)

datasets, data_info = tfds.load('malaria', split='train', as_supervised=True, with_info=True, shuffle_files=True)

def splits(TRAIN_RATIO, VAL_RATIO, TEST_RATIO, dataset):
  DATASET_SIZE = len(dataset)

  train_dataset = dataset.take(int(TRAIN_RATIO * DATASET_SIZE))

  val_test_dataset = dataset.skip(int(TRAIN_RATIO * DATASET_SIZE))

  val_dataset = val_test_dataset.take(int(VAL_RATIO * DATASET_SIZE))

  test_dataset = val_test_dataset.skip(int(VAL_RATIO*DATASET_SIZE))
  return train_dataset, val_dataset, test_dataset

TRAIN_RATIO = 0.6
VAL_RATIO = 0.2
TEST_RATIO = 0.2

# datasets = tf.data.Dataset.range(10)
train_dataset, val_dataset, test_dataset = splits(TRAIN_RATIO, VAL_RATIO, TEST_RATIO, datasets)
# print(list(train_dataset.take(1).as_numpy_iterator()), list(val_dataset.take(1).as_numpy_iterator()),
#       list(test_dataset.take(1).as_numpy_iterator()))

for i, (image, label) in enumerate(train_dataset.take(16)):
  plt.subplot(4,4, i+1)
  plt.imshow(image)
  plt.title(data_info.features['label'].int2str(label))
  plt.axis('off')

"""*DATA_PREPROCESSING*"""

IMG_SIZE = 224
def resizing_rescale(image, label):
  return tf.image.resize(image, (IMG_SIZE,IMG_SIZE))/255.0, label

"""*DATA_VISUALIZATION*"""

# def visulize(original, augmented):
#   plt.subplot(1,2,1)
#   plt.imshow(original)

#   plt.subplot(1,2,2)
#   plt.imshow(augmented)

# original_image, label = next(iter(train_dataset.take(1)))
# original_image = original_image[0] # Select the first image from the batch
# label = label[0] # Select the first label from the batch

"""***DATA_AUGMENTAION***"""

## tf.image
# def augment(image, label):
#   image, label = resizing_rescale(image, label)
#   image = tf.image.rot90(image)
#   # image = tf.image.adjust_saturation(image, saturation_factor=0.3)
#   image = tf.image.flip_left_right(image)
#   return image, label

"""***Custom_layer_augmentation_with_tf.image***"""

class AugmentLayerCustom(Layer):
  def __init__(self):
      super().__init__()

  def call(self, image):
    return tf.image.rot90(image)

## tf.keras.flip

augment_layer = tf.keras.Sequential([
    RandomFlip(mode='horizontal'),
    AugmentLayerCustom()
    # RandomRotation(factor=(0.25, 0.2501))
])
resizing_rescale = tf.keras.Sequential([
    Resizing(IMG_SIZE, IMG_SIZE),
    Rescaling(1.0/255)
])
# def augment_layer(image, labels):
#   # image, label = resizing_rescale(image, labels)
#   return augment_layer_s(resizing_rescale(image), training=True),labels

"""***how to generate bounding_box***"""

def box(lamda):
    r_x = tf.cast(tfp.distributions.Uniform(low=0, high=IMG_SIZE).sample(1)[0], dtype=tf.int32)
    r_y = tf.cast(tfp.distributions.Uniform(low=0, high=IMG_SIZE).sample(1)[0], dtype=tf.int32)

    r_w = tf.cast(IMG_SIZE*tf.math.sqrt(1-lamda), dtype=tf.int32)
    r_h = tf.cast(IMG_SIZE*tf.math.sqrt(1-lamda), dtype=tf.int32)

    offset_rx = tf.clip_by_value(r_x - r_w//2, 0, IMG_SIZE)
    offset_ry =tf.clip_by_value(r_y - r_w//2, 0, IMG_SIZE)

    x_b_r = tf.clip_by_value(r_x + r_w//2, 0, IMG_SIZE)
    y_b_r =tf.clip_by_value(r_y + r_w//2, 0, IMG_SIZE)

    r_w = x_b_r - offset_rx
    if r_w == 0:
      r_w = 1
    r_h = y_b_r - offset_ry
    if r_h == 0:
      r_h = 1

    return offset_ry, offset_rx, r_h, r_w

"""***cut_augmenetaion***"""

lena_img = cv2.imread('/content/lena.jpg')
lena_img = cv2.resize(lena_img, (224,224))

messi_img = cv2.imread('/content/messi5.jpg')
messi_img = cv2.resize(messi_img, (224,224))

plt.subplot(1,7,1)
plt.imshow(lena_img)

plt.subplot(1,7,2)
plt.imshow(messi_img)

lamda = tfp.distributions.Beta(0.2,0.2)
lamda = lamda.sample(1)[0]
offset_ry, offset_rx, r_h, r_w = box(lamda)

crop_lena = tf.image.crop_to_bounding_box(lena_img, offset_ry, offset_rx, r_h, r_w) #20, 100, 130, 120
plt.subplot(1,7,3)
plt.imshow(crop_lena)

crop_messi = tf.image.crop_to_bounding_box(messi_img, offset_ry, offset_rx, r_h, r_w) #20, 100, 130, 120
plt.subplot(1,7,4)
plt.imshow(crop_messi)

pad_img_1 = tf.image.pad_to_bounding_box(crop_lena, offset_ry, offset_rx, 224, 224) #20, 100
plt.subplot(1,7,5)
plt.imshow(pad_img_1)

pad_img_2 = tf.image.pad_to_bounding_box(crop_messi, offset_ry, offset_rx, 224, 224) #20, 100
plt.subplot(1,7,6)
plt.imshow(messi_img - pad_img_2 + pad_img_1)

train_dataset_1 = train_dataset.shuffle(buffer_size = 8, reshuffle_each_iteration=True)
train_dataset_2 = train_dataset.shuffle(buffer_size = 8, reshuffle_each_iteration=True)

 # Explicitly set training to False for preprocessing

def mixup(ds1, ds2):
    image_1, label_1 = ds1
    image_2, label_2 = ds2

    lamda = tfp.distributions.Beta(0.6,0.1)
    lamda = lamda.sample(1)[0]
    image = lamda*image_1 + (1-lamda)*image_2
    label = lamda*label_1 + (1-lamda)*label_2
    return image, label

# train_dataset_1 = train_dataset_1.map(resizing_rescale)
# train_dataset_2 = train_dataset_2.map(resizing_rescale)

train_dataset_mixed = tf.data.Dataset.zip((train_dataset_1, train_dataset_2))

"""***Albumentation***"""

transforms = A.Compose([
    A.Resize(224, 224),
    A.OneOf([
        A.HorizontalFlip(p=0.5),
        A.VerticalFlip(p=0.5)]),
    A.RandomBrightnessContrast(brightness_limit=0.2,
                               contrast_limit=0.2,
                               p=0.5),
])

def process_data(image, label):
  aug_img = tf.numpy_function(func=aug_albument, inp=[image], Tout= tf.float32)
  return aug_img, label

test_dataset = (test_dataset
                .map(resizing_rescale)
                )

train_dataset =(train_dataset.shuffle(buffer_size = 8, reshuffle_each_iteration=True)
.map(resizing_rescale)
.batch(32)
.prefetch(tf.data.AUTOTUNE))

val_dataset = (val_dataset.shuffle(buffer_size = 8, reshuffle_each_iteration=True)
.map(resizing_rescale)
.batch(32)
.prefetch(tf.data.AUTOTUNE))
train_dataset

val_dataset

# lenet_model = tf.keras.Sequential([
#     InputLayer(input_shape = (IMG_SIZE, IMG_SIZE, 3)),

#     Conv2D(filters= 6, kernel_size=3, strides=1, padding='valid', activation='relu'),
#     BatchNormalization(),
#     MaxPool2D(pool_size=2, strides=2),

#     Conv2D(filters= 16, kernel_size=3, strides=1, padding='valid', activation='relu'),
#     BatchNormalization(),
#     MaxPool2D(pool_size=2, strides=2),

#     Flatten(),
#     Dense(100, activation='relu'),
#     BatchNormalization(),
#     Dense(10, activation='relu'),
#     BatchNormalization(),
#     Dense(1, activation='sigmoid'),
# ])
# lenet_model.summary()

"""ResNet_Model"""

# func_input = Input(shape = (IMG_SIZE, IMG_SIZE, 3), name= 'lenet_model')
# x = Conv2D(filters= 6, kernel_size=3, strides=1, padding='valid', activation='relu')(func_input)
# x = BatchNormalization()(x)
# x = MaxPool2D(pool_size=2, strides=2)(x)
# x = Conv2D(filters= 16, kernel_size=3, strides=1, padding='valid', activation='relu')(x)
# x = BatchNormalization()(x)
# x = MaxPool2D(pool_size=2, strides=2)(x)

# x = Flatten()(x)

# x = Dense(100, activation='relu')(x)
# x = BatchNormalization()(x)
# x = Dense(10, activation='relu')(x)
# x = BatchNormalization()(x)

# func_output = Dense(1, activation='sigmoid')(x)
# lenet_model = Model(func_input, func_output, name = 'lenet_model')
# lenet_model.summary()

"""*feature_extractor_model_and_functional_api*"""

# func_input = Input(shape = (IMG_SIZE, IMG_SIZE, 3), name= 'lenet_model')
# x = Conv2D(filters= 6, kernel_size=3, strides=1, padding='valid', activation='relu')(func_input)
# x = BatchNormalization()(x)
# x = MaxPool2D(pool_size=2, strides=2)(x)
# x = Conv2D(filters= 16, kernel_size=3, strides=1, padding='valid', activation='relu')(x)
# x = BatchNormalization()(x)
# func_output = MaxPool2D(pool_size=2, strides=2)(x)

# feature_extractor_model = Model(func_input, func_output, name = 'Feature_ Extractor')
# feature_extractor_model.summary()

# func_input = Input(shape = (IMG_SIZE, IMG_SIZE, 3), name= 'lenet_model')

# x = feature_extractor_model(func_input)

# x = Flatten()(x)

# x = Dense(100, activation='relu')(x)
# x = BatchNormalization()(x)
# x = Dense(10, activation='relu')(x)
# x = BatchNormalization()(x)

# func_output = Dense(1, activation='sigmoid')(x)
# lenet_model = Model(func_input, func_output, name = 'lenet_model')
# lenet_model.summary()

"""***Model_Subclassing***"""

class FeatureExtractor(Layer):
  def __init__(self, filters, kernel_size, strides, padding, activation, pool_size):
    super(FeatureExtractor, self).__init__()

    self.conv_1 = Conv2D(filters= filters, kernel_size= kernel_size , strides= strides, padding= padding, activation= activation)
    self.batch_1 = BatchNormalization()
    self.pool_1 = MaxPool2D(pool_size= pool_size, strides=2*strides)

    self.conv_2 = Conv2D(filters= filters*2, kernel_size= kernel_size , strides= strides, padding= padding, activation= activation)
    self.batch_2 = BatchNormalization()
    self.pool_2 =  MaxPool2D(pool_size= pool_size, strides=2*strides)

  def call(self, x):
    x = self.conv_1(x)
    x = self.batch_1(x)
    x = self.pool_1(x)
    x = self.conv_2(x)
    x = self.batch_2(x)
    x = self.pool_2(x)
    return x

class_feature = FeatureExtractor(8, 3, 1, 'valid', 'relu', 2)

func_input = Input(shape = (IMG_SIZE, IMG_SIZE, 3), name= 'lenet_model')

# x = class_feature(func_input)

# x = Flatten()(x)

# x = Dense(100, activation='relu')(x)
# x = BatchNormalization()(x)
# x = Dense(10, activation='relu')(x)
# x = BatchNormalization()(x)

# func_output = Dense(1, activation='sigmoid')(x)
# lenet_model = Model(func_input, func_output, name = 'lenet_model')
# lenet_model.summary()

class LenetModel(Model):
  def __init__(self):
    super(LenetModel, self).__init__()

    self.feature_extractor = FeatureExtractor(8, 3, 1, 'valid', 'relu', 2)
    self.flatten =  Flatten()

    self.dense_1 =Dense(100, activation = 'relu')
    self.batch_1 = BatchNormalization()
    self.dense_2 =Dense(10, activation = 'relu')
    self.batch_2 = BatchNormalization()
    self.dense_3 =Dense(1, activation = 'sigmoid')
  def call(self, x):
    x = self.feature_extractor(x)
    x = self.flatten(x)

    x = self.dense_1(x)
    x = self.batch_1(x)
    x = self.dense_2(x)
    x = self.batch_2(x)
    x = self.dense_3(x)
    return x
lenet_model = LenetModel()
lenet_model(tf.zeros([1,224,224,3]))
lenet_model.summary()

"""***custom_layer***"""

class CustomlayerDense(Layer):
   def __init__(self, output_units, activation):
    super(CustomlayerDense, self).__init__()
    self.output_units = output_units
    self.activation = activation

   def build(self, input_shape):
      self.w = self.add_weight(shape = (input_shape[-1], self.output_units), initializer = 'random_normal', trainable= True)
      self.b = self.add_weight(shape = (self.output_units,), initializer = 'random_normal', trainable= True)

   def call(self, input_feature):
      pre_output = tf.matmul( input_feature, self.w) + self.b
      if (self.activation == 'relu'):
        return tf.nn.relu(pre_output)

      elif (self.activation == 'sigmoid'):
        return tf.math.sigmoid(pre_output)

      else:
        return pre_output

def model_tune(hparams):
  lenet_model = tf.keras.Sequential([
      InputLayer(input_shape = (IMG_SIZE, IMG_SIZE, 3)),
      # resizing_rescale,
      # augment_layer,
      Conv2D(filters= 6, kernel_size=3, strides=1, padding='valid', activation='relu'),
      BatchNormalization(),
      MaxPool2D(pool_size=2, strides=2),
      Dropout(rate = hparams['HP_DROPOUT']),

      Conv2D(filters= 16, kernel_size=3, strides=1, padding='valid', activation='relu'),
      BatchNormalization(),
      MaxPool2D(pool_size=2, strides=2),

      Flatten(),
      Dense(hparams['HP_NUM_UNITS_1'], activation='relu'),
      BatchNormalization(),
      Dropout(rate = hparams['HP_DROPOUT']),

      Dense(hparams['HP_NUM_UNITS_2'], activation='relu'),
      BatchNormalization(),
      Dense(1, activation='sigmoid'),
  ])
  # lenet_model.summary()
  lenet_model.compile(
    optimizer = Adam(learning_rate=hparams['HP_LEARNING_RATE']),
    loss = CustomLoss(FACTOR),
    metrics = [BinaryAccuracy(name='acc')]
  )
  lenet_model.fit(val_dataset, epochs=1)
  _, accuracy = lenet_model.evaluate(val_dataset)
  return accuracy

HP_NUM_UNITS_1 = hp.HParam('num_units_1', hp.Discrete([16, 32, 64, 128]))
HP_NUM_UNITS_2 = hp.HParam('num_units_2', hp.Discrete([16, 32, 64, 128]))
HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.1,0.2,0.3]))
HP_LEARNING_RATE = hp.HParam('learning_rate', hp.Discrete([1e-4, 1e-3]))

run_number = 0
for num_units_1 in HP_NUM_UNITS_1.domain.values:
  for num_units_2 in HP_NUM_UNITS_2.domain.values:
    for dropout in HP_DROPOUT.domain.values:
      for learning_rate in HP_LEARNING_RATE.domain.values:

        hparams = {
            "HP_NUM_UNITS_1": num_units_1,
            "HP_NUM_UNITS_2": num_units_2,
            "HP_DROPOUT": dropout,
            "HP_LEARNING_RATE": learning_rate
        }
        file_writer = tf.summary.create_file_writer('logs/'+ str(run_number))
        run_number += 1

        with file_writer.as_default():
          hp.hparams(hparams)
          accuracy = model_tune(hparams)
          tf.summary.scalar('accuracy', accuracy, step=run_number)

metrics = [FalseNegatives(name='Fn'), FalsePositives(name='Fp'), TrueNegatives(name='Tn'), TruePositives(name='Tp'), BinaryAccuracy(name='acc'),
           Precision(name='precision'), Recall(name='recall'),AUC(name='auc')]

"""***callbacks***"""

class LossCallBack(Callback):
  def on_epoch_end(self, epoch, logs):
    print('\n for epoch {} the model has a log {}'.format(epoch+1, logs['loss']))

csv_logger = CSVLogger('logs.csv', separator=',', append=False)

es_stopping = EarlyStopping(
    monitor='val_loss',
    min_delta=0,
    patience=2,
    verbose=1,
    mode='auto',
    baseline=None,
    restore_best_weights=False
)

# add manually learning_rate to tensorboard

METRIC_DIR = './logs/metrics'
train_writet = tf.summary.create_file_writer(METRIC_DIR)

def scheduler(epoch, lr):
  if epoch <= 2:
    return lr
  else:
    return lr * tf.math.exp(-0.1)
  with train_writer.as_difault():
    tf.summary.scalar('Learning_rate', lr, epoch)
scheduler_callback = LearningRateScheduler(scheduler, verbose=1)

"""***TensorBoard***"""

LOG_DIR = './logs'
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR)

"""***Custom_loss and Custom_metrics***"""

FACTOR = 1
class CustomLoss(tf.keras.losses.Loss):
  def __init__(self, name='custom_loss'):
    super(CustomLoss, self).__init__()
    self.FACTOR = FACTOR
  def call(self, y_true, y_pred):
    bce = BinaryCrossentropy()
    return bce(y_true, y_pred) * self.FACTOR

class CustomMetric(tf.keras.metrics.Metric):
    def __init__(self, name='custom_metric', **kwargs):
        super(CustomMetric, self).__init__(name=name, **kwargs)
        self.total = self.add_weight(name='total', initializer='zeros')
        self.count = self.add_weight(name='count', initializer='zeros')

    def update_state(self, y_true, y_pred, sample_weight=None):
        y_true = tf.cast(y_true, dtype=tf.float32)
        y_pred = tf.cast(y_pred > 0.5, dtype=tf.float32) # Convert predictions to binary

        correct_predictions = tf.cast(tf.equal(y_true, y_pred), dtype=tf.float32)
        self.total.assign_add(tf.reduce_sum(correct_predictions))
        self.count.assign_add(tf.cast(tf.shape(y_true)[0], dtype=tf.float32))


    def result(self):
        return self.total / self.count

    def reset_states(self):
        self.total.assign(0.0)
        self.count.assign(0.0)

lenet_model.compile(
    optimizer = Adam(learning_rate=0.01),
    loss = CustomLoss(FACTOR),
    metrics = [BinaryAccuracy(name='acc')]
)

"""***Custom_fit***"""

epochs = 5
METRIC = BinaryAccuracy()
METRIC_VAL = BinaryAccuracy()
OPTIMEZER = Adam(learning_rate=0.01)

@tf.function
def train_step(x_batch, y_batch):
  with tf.GradientTape() as Tape:
      y_pred = lenet_model(x_batch, training=True)
      loss = CustomLoss(FACTOR)(y_batch, y_pred)

      partial_drivatives = Tape.gradient(loss, lenet_model.trainable_weights)
      OPTIMEZER.apply_gradients(zip(partial_drivatives, lenet_model.trainable_weights))

      METRIC.update_state(y_batch, y_pred)
  return loss

@tf.function
def val_setp (x_batch_val, y_batch_val):
      y_pred_val = lenet_model(x_batch_val, training=False)
      loss_val = CustomLoss(FACTOR)(y_batch_val, y_pred_val)
      METRIC_VAL.update_state(y_batch_val, y_pred_val)
      return loss_val

def custom_neurallearn(epochs, train_dataset, val_dataset, OPTIMEZER, METRIC, METRIC_VAL):
  for epoch in range(epochs):
    for step, (x_batch, y_batch) in enumerate(train_dataset):
      loss = train_step(x_batch, y_batch)
      if step%100 ==0:
        print(loss)

    print('accuracy is : ', METRIC.result())
    METRIC.reset_state()

    for step, (x_batch_val, y_batch_val) in enumerate(val_dataset):
      loss_val = val_setp(x_batch_val, y_batch_val)
      if step%100 ==0:
          print(loss_val)

    print('accuracy_val is : ', METRIC_VAL.result())
    METRIC_VAL.reset_state()

custom_neurallearn(epochs, train_dataset, val_dataset, OPTIMEZER, METRIC, METRIC_VAL)

history = lenet_model.fit(train_dataset, validation_data=val_dataset, epochs=3, verbose=1,
                          callbacks=[tensorboard_callback, scheduler_callback])#LossCallBack()[csv_logger, es_stopping, scheduler_callback]

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

"""***visualization_tensorboard***"""

tensorboard --logdir='./logs'

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model_loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val_loss'])
plt.show()

test_dataset = test_dataset.batch(1)

lenet_model.evaluate(test_dataset)

def parasite_or_not(x):
  if x < 0.5:
    return str('U')
  else:
    return str('P')

parasite_or_not(lenet_model.predict(test_dataset.take(1))[0][0])

for i, (image, label) in enumerate(test_dataset.take(9)):
  plt.subplot(3,3, i+1)
  plt.imshow(image[0])
  plt.title(str(parasite_or_not(label.numpy()[0]))+ ':' + str(parasite_or_not(lenet_model.predict(image)[0][0])))
  plt.axis('off')

"""***tp,fp,tn,fn visualization***"""

labels = []
inp = []
for x,y in test_dataset.as_numpy_iterator():
  labels.append(y)
  inp.append(x)

labels = np.array([i for i in labels])
labels = labels[:2000]

# predicted = lenet_model.predict(np.array(inp[:2000]))



# fp, tp, threshold = roc_curve(labels, predicted)

threshold = 0.75

cm = confusion_matrix(labels, predicted > threshold)
plt.figure(figsize=(8,8))

sns.heatmap(cm, annot=True)
plt.title('Confiusion matrix {}'.format(threshold))
plt.ylabel('Actual')
plt.xlabel('predicted')

"""***ROC_PLOT***"""

inp[:2000]