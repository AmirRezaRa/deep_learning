# -*- coding: utf-8 -*-
"""Customer_churn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FxvTBBuNpnz0OoZ-KaxbhX7soeC6qqcU
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

data = pd.read_csv("/content/Telco Customer Churn.csv")
data.sample(5)

data.drop('customerID', axis=1,inplace=True)

data1 = data[data.TotalCharges!= ' ']
data1.TotalCharges = pd.to_numeric(data1.TotalCharges)
data1.dtypes

tenure_churn_no = data1[data1.Churn=='No'].tenure
tenure_churn_yes = data1[data1.Churn=='Yes'].tenure
plt.hist([tenure_churn_no,tenure_churn_yes])
plt.xlabel('tenure')
plt.ylabel('numbers of customers')
plt.legend(('churn_no','churn_yes'))

for column in data1:
  print(f"{column} : {data1[column].unique()}")

yes_no_columns = ['Partner', 'Dependents','PhoneService','MultipleLines','InternetService','OnlineSecurity','OnlineBackup','DeviceProtection',
                  'TechSupport','StreamingTV','StreamingMovies','PaperlessBilling','Churn']
data1.replace('No internet service', 'No', inplace=True)
data1.replace('No phone service', 'No', inplace=True)
for column in yes_no_columns:
  data1[column].replace({'Yes':1, 'No':0}, inplace=True)

data1['gender'].replace({'Female':1,'Male':0}, inplace=True)
data2 = pd.get_dummies(data=data1, columns=['InternetService','Contract','PaymentMethod'],dtype=int)

for column in data2:
  print(f"{column} : {data2[column].unique()}")

cols_to_scale = ['tenure', 'MonthlyCharges', 'TotalCharges']
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
data2[cols_to_scale] = scaler.fit_transform(data2[cols_to_scale])

X = data2.drop('Churn', axis='columns')
Y = data2['Churn']
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=5)

import tensorflow as tf
from tensorflow import keras
from sklearn.metrics import confusion_matrix, classification_report

def ANN(x_train, y_train, x_test, y_test, epochs):

  model = keras.Sequential([
      keras.layers.Dense(26, input_shape=(26,), activation='relu'),
      keras.layers.Dense(15, activation='relu'),
      keras.layers.Dense(1, activation='sigmoid')
  ])

  model.compile(
      optimizer='adam',
      loss = 'binary_crossentropy',
      metrics=['accuracy']
  )
  model.fit(x_train, y_train, epochs)
  print(model.evaluate(x_test, y_test))

  prediction = model.predict(x_test)
  y_pred=[]
  for element in prediction:
    if element > 0.5:
      y_pred.append(1)
    else:
      y_pred.append(0)

  print(classification_report(y_test, y_pred))
  return y_pred

y_pred = ANN(x_train, y_train, x_test, y_test, epochs=50)
print(y_pred[:5])

"""# **METHOD1 :**  **UNNDER SAMPLING MAJORITY**"""

df2_class0_num, df2_class1_num = data2.Churn.value_counts()
df2_class0 = data2[data2['Churn'] == 0]
df2_class1 = data2[data2['Churn'] == 1]

df2_class0.shape , df2_class1.shape

df2_class0_under = df2_class0.sample(df2_class1_num)
df2_new_under = pd.concat([df2_class0_under,df2_class1], axis=0)

from sklearn.model_selection import train_test_split

X = df2_new_under.drop('Churn', axis='columns')
Y = df2_new_under['Churn']
x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=15, stratify=Y)

y_pred = ANN(x_train, y_train, x_test, y_test, epochs=50)

"""# **NETHOD2**: **OVERSAMPLING**"""

df2_class1_over = df2_class1.sample(df2_class0_num, replace=True)
df2_new_over = pd.concat([df2_class1_over,df2_class0], axis=0)

X = df2_new_over.drop('Churn', axis='columns')
Y = df2_new_over['Churn']
x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=15, stratify=Y)

y_pred = ANN(x_train, y_train, x_test, y_test, epochs=50)

"""# **# method 3 :** **smoothing**"""

# pip install imblearn

from imblearn.over_sampling import SMOTE
smote = SMOTE(sampling_strategy='minority')
x_res, y_res = smote.fit_resample(X,Y)

x_train, x_test, y_train, y_test = train_test_split(x_res, y_res, test_size=0.2, random_state=15, stratify=y_res)

"""# **method 4: ensemble method**"""

# X = data2.drop('Churn', axis='columns')
# Y = data2['Churn']
# from sklearn.model_selection import train_test_split
# x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=5)

df2_class0_num, df2_class1_num = data2.Churn.value_counts()
df2_class0 = data2[data2['Churn'] == 0]
df2_class1 = data2[data2['Churn'] == 1]

import seaborn as sn
cm = tf.math.confusion_matrix(labels=y_test, predictions=y_pred)

plt.figure(figsize=(10,7))
sn.heatmap(cm, annot=True, fmt='d')
plt.xlabel('prediction')
plt.ylabel('Truth')